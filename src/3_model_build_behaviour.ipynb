{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Build the KNN model \n",
    "\n",
    "Now that the data is prepared we can build the model for predictions an evaluations. <br>\n",
    "I will be using the K nearest neighbours model to find organisations that are similar to each other. \n",
    "\n",
    "## Model 2: Customer behaviour\n",
    "\n",
    "This model will run KNN based on synthetic customer behaviour"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///../data/orgs_customer_behaviours.db')\n",
    "df_normalised_features = pd.read_sql_table('synth_customer_behaviour_data', engine)\n",
    "df_features = pd.read_sql_table('synth_customer_target_classifier_data', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_normalised_features\n",
    "y = df_features['CONVERTED']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "num_neighbors = 1\n",
    "knn = KNeighborsClassifier(n_neighbors=num_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'WITH K={num_neighbors}\\n')\n",
    "print('\\nCONFUSION MATRIX:')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('\\nCLASSIFICATION REPORT:')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "source": [
    "#### Improve the model with a better K value\n",
    "The initial K value was arbitrary to prove the functioning of the model. <br>\n",
    "Lets try to improve accuracy by finding a better K value for KNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "\n",
    "for i in range(1, 40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neighbors = 40\n",
    "knn = KNeighborsClassifier(n_neighbors=num_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'WITH K={num_neighbors}\\n')\n",
    "print('\\nCONFUSION MATRIX:')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('\\nCLASSIFICATION REPORT:')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parameters = {\n",
    "    'n_neighbors': [5, 10, 18, 20, 25, 35, 40],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(KNeighborsClassifier(), grid_parameters, verbose=1, cv=3, n_jobs=-1)\n",
    "\n",
    "gs_results = gs.fit(X_train, y_train)\n",
    "\n",
    "print(f'\\n\\nBest scores found are {gs_results.best_score_}\\n\\n')\n",
    "print(f'Best results are found using estimator {gs_results.best_estimator_}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neighbors = 10\n",
    "knn = KNeighborsClassifier(n_neighbors=num_neighbors, weights='distance', metric='manhattan')\n",
    "knn.fit(X_train, y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "print(f'WITH K={num_neighbors}\\n')\n",
    "print('\\nCONFUSION MATRIX:')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('\\nCLASSIFICATION REPORT:')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "source": [
    "### PCA\n",
    "\n",
    "Lets reduce the dimensions to see if we can improve the outcomes and vizualise the model for analysis."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "X_train_n2 = pca.fit_transform(X_train)\n",
    "knn.fit(X_train_n2, y_train)\n",
    "\n",
    "print(f'WITH K={num_neighbors}\\n')\n",
    "print('\\nCONFUSION MATRIX:')\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print('\\nCLASSIFICATION REPORT:')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  X_npa = X_train_n2.to_numpy()\n",
    "y_npa = y_train.to_numpy()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [25, 20]\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Knn with K='+ str(num_neighbors))\n",
    "plot_decision_regions(X_train_n2, y_npa, clf=knn, legend=2, colors='blue,grey,darkblue,darkgrey', markers='^s')# Adding axes annotations\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}